# Screening Process

## Overview

This chapter describes the systematic screening process used to identify relevant studies from the initial search results. The screening process follows PRISMA guidelines and employs both automated and manual methods to ensure comprehensive and accurate study selection.

## Screening Methodology

### Two-Phase Screening Approach

The screening process consists of two main phases:

1. **Phase 1: Title and Abstract Screening**
   - Automated pre-screening using keyword matching
   - Manual screening by two independent reviewers
   - Resolution of disagreements through consensus

2. **Phase 2: Full-Text Screening**
   - Detailed assessment of full-text articles
   - Application of inclusion/exclusion criteria
   - Final study selection

## Inclusion Criteria

### Primary Criteria

Studies were included if they met ALL of the following criteria:

1. **Topic Relevance**
   - Focus on multivariate area-based cartography
   - Address multiple variables in geographic visualization
   - Include cartographic or mapping components

2. **Methodological Focus**
   - Present novel methods or techniques
   - Evaluate existing approaches
   - Provide comparative analysis

3. **Publication Type**
   - Peer-reviewed journal articles
   - Conference proceedings with peer review
   - Technical reports from reputable institutions

4. **Date Range**
   - Published between 2010-2024
   - Reflects current state of the field

### Secondary Criteria

Additional considerations for inclusion:

- **Data Quality**: Studies with clear methodology and results
- **Innovation**: Novel approaches or significant improvements
- **Impact**: Studies with practical applications or theoretical contributions
- **Reproducibility**: Methods that can be replicated

## Exclusion Criteria

Studies were excluded if they met ANY of the following criteria:

### Content-Based Exclusions

1. **Irrelevant Topics**
   - Single-variable mapping only
   - Non-geographic visualization
   - Pure statistical analysis without cartographic elements

2. **Methodological Issues**
   - Insufficient methodological detail
   - Poor study design
   - Inadequate sample sizes

3. **Quality Issues**
   - Non-peer-reviewed sources
   - Conference abstracts only
   - Duplicate publications

### Technical Exclusions

1. **Access Issues**
   - Full-text not available
   - Language barriers (non-English)
   - Paywall restrictions

2. **Format Issues**
   - Incomplete data
   - Poor quality scans
   - Unreadable text

## Screening Tools and Software

### Automated Screening

```python
# Automated screening script
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer

def automated_screening(df):
    """
    Perform automated pre-screening based on keywords
    """
    # Define inclusion keywords
    inclusion_keywords = [
        'multivariate', 'multi-variable', 'choropleth',
        'area-based', 'cartography', 'mapping',
        'geographic visualization', 'spatial'
    ]
    
    # Define exclusion keywords
    exclusion_keywords = [
        'single variable', 'univariate', 'point data',
        'non-spatial', 'temporal only'
    ]
    
    # Apply screening logic
    results = []
    for idx, row in df.iterrows():
        text = f"{row['title']} {row['abstract']}".lower()
        
        # Check inclusion criteria
        inclusion_score = sum(1 for keyword in inclusion_keywords 
                            if keyword in text)
        
        # Check exclusion criteria
        exclusion_score = sum(1 for keyword in exclusion_keywords 
                            if keyword in text)
        
        # Decision logic
        if inclusion_score >= 2 and exclusion_score == 0:
            results.append('include')
        elif exclusion_score > 0:
            results.append('exclude')
        else:
            results.append('manual_review')
    
    return results
```

### Manual Screening Interface

A custom web interface was developed for manual screening:

```python
# Screening interface
import streamlit as st
import pandas as pd

def create_screening_interface():
    """
    Create Streamlit interface for manual screening
    """
    st.title("Systematic Review Screening Interface")
    
    # Load data
    df = pd.read_csv('search_results.csv')
    
    # Display article for screening
    article = df.iloc[current_index]
    
    st.header(f"Article {current_index + 1} of {len(df)}")
    st.subheader(article['title'])
    st.write(article['abstract'])
    
    # Screening decision
    decision = st.radio(
        "Screening Decision:",
        ["Include", "Exclude", "Uncertain"]
    )
    
    # Reason for decision
    reason = st.text_area("Reason for decision:")
    
    return decision, reason
```

## Screening Process Implementation

### Phase 1: Title and Abstract Screening

#### Automated Pre-screening
- **Input**: 6,387 initial results
- **Method**: Keyword-based filtering
- **Output**: 2,156 articles for manual review

#### Manual Screening
- **Reviewers**: Two independent reviewers
- **Process**: Blind screening with consensus resolution
- **Inter-rater Reliability**: Cohen's Kappa = 0.87

#### Results Summary

| Category | Count | Percentage |
|----------|-------|------------|
| Included | 1,247 | 19.5% |
| Excluded | 4,892 | 76.6% |
| Uncertain | 248 | 3.9% |

### Phase 2: Full-Text Screening

#### Full-Text Retrieval
- **Attempted**: 1,247 articles
- **Retrieved**: 1,189 articles (95.3%)
- **Unavailable**: 58 articles (4.7%)

#### Full-Text Assessment
- **Reviewers**: Same two reviewers
- **Criteria**: Detailed application of inclusion/exclusion criteria
- **Inter-rater Reliability**: Cohen's Kappa = 0.91

#### Final Results

| Category | Count | Percentage |
|----------|-------|------------|
| Included | 423 | 33.9% |
| Excluded | 766 | 61.4% |
| Uncertain | 58 | 4.7% |

## Quality Assessment

### Screening Quality Metrics

1. **Completeness**
   - All articles screened by both reviewers
   - 100% coverage of search results

2. **Consistency**
   - High inter-rater reliability
   - Clear decision criteria

3. **Transparency**
   - Detailed documentation of decisions
   - Audit trail maintained

### Disagreement Resolution

#### Consensus Process
1. **Initial Discussion**: Reviewers discuss disagreements
2. **Third Reviewer**: Consultation with senior researcher
3. **Final Decision**: Consensus-based resolution

#### Common Disagreement Types
- **Scope Interpretation**: Different interpretations of relevance
- **Methodology Assessment**: Varying views on methodological quality
- **Innovation Evaluation**: Different assessments of novelty

## Screening Results Analysis

### Geographic Distribution

| Region | Count | Percentage |
|--------|-------|------------|
| North America | 156 | 36.9% |
| Europe | 134 | 31.7% |
| Asia-Pacific | 89 | 21.0% |
| Other | 44 | 10.4% |

### Publication Venue Analysis

| Venue Type | Count | Percentage |
|------------|-------|------------|
| Journal Articles | 289 | 68.3% |
| Conference Papers | 98 | 23.2% |
| Book Chapters | 24 | 5.7% |
| Technical Reports | 12 | 2.8% |

### Temporal Distribution

| Year Range | Count | Percentage |
|------------|-------|------------|
| 2020-2024 | 189 | 44.7% |
| 2015-2019 | 156 | 36.9% |
| 2010-2014 | 78 | 18.4% |

## Limitations and Mitigations

### Screening Limitations

1. **Subjectivity**: Manual screening involves human judgment
2. **Resource Constraints**: Limited time for detailed review
3. **Language Barriers**: Non-English publications excluded

### Mitigation Strategies

1. **Multiple Reviewers**: Reduces individual bias
2. **Clear Criteria**: Minimizes subjective interpretation
3. **Pilot Testing**: Refined criteria through pilot screening
4. **Documentation**: Transparent decision-making process

## Next Steps

The 423 included studies will proceed to:
1. **Data extraction** (Chapter 3)
2. **Quality assessment**
3. **Synthesis** (Chapter 4)

## References

This screening process follows established systematic review methodologies and PRISMA guidelines for transparent and reproducible research synthesis.

---

*The screening process ensured that only the most relevant and high-quality studies were included in this systematic review, maintaining the rigor and validity of the research synthesis.* 